{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Manual Construction of Lexers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><img src=\"pictures/compiler.jpg\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Recognition of Tokens\n",
    "\n",
    "The manual construction of a lexical analyzer involves several steps:\n",
    "\n",
    "1. **Describe Lexical Patterns:**\n",
    "   - Define regular expressions (RE) to describe the lexical pattern of each token type.\n",
    "\n",
    "2. **Construct NFAs:**\n",
    "   - Create Non-deterministic Finite Automata (NFAs) for each regular expression.\n",
    "\n",
    "3. **Convert NFAs to DFAs:**\n",
    "   - Convert the NFAs to Deterministic Finite Automata (DFAs) for efficiency.\n",
    "\n",
    "4. **Minimize DFA States:**\n",
    "   - Minimize the number of states in the DFAs where possible.\n",
    "\n",
    "5. **Construct Transition Diagrams:**\n",
    "   - Build lexical analyzer transition diagrams from the DFAs.\n",
    "\n",
    "6. **Implement Transition Diagrams:**\n",
    "   - Translate the transition diagrams into actual code for the lexical analyzer.\n",
    "\n",
    "#### Transition Diagrams: Notations\n",
    "\n",
    "As an intermediate step, patterns are converted into stylized flowcharts called \"transition diagrams.\" These diagrams incorporate DFAs for recognizing tokens. If it's necessary to retract the forward pointer one position (i.e., the lexeme doesn't include the symbol that got us to the accepting state), a '*' is placed near that accepting state.\n",
    "\n",
    "#### Transition Diagram Examples:\n",
    "\n",
    "1. **Relational Operations (RELOPs):**\n",
    "   - Diagram for recognizing relational operators like `<`, `<>`, `=`, `>=`, `<=`, `==`, etc.\n",
    "\n",
    "# <center><img src=\"pictures/RELOPs.JPG\" width=\"600\"/>\n",
    "\n",
    "2. **Reserved Words and Identifiers:**\n",
    "   - Diagram for recognizing reserved words and identifiers in the source code.\n",
    "\n",
    "# <center><img src=\"pictures/identifers.JPG\" width=\"600\"/>\n",
    "\n",
    "3. **Unsigned Numbers:**\n",
    "   - Diagram for recognizing unsigned numerical values.\n",
    "\n",
    "# <center><img src=\"pictures/unsigned-numbers.JPG\" width=\"600\"/>\n",
    "\n",
    "#### Lexer Input and Output:\n",
    "\n",
    "The lexical analyzer takes the source code as input and produces a stream of tokens as output. This token stream is then passed to the parser for further syntactic analysis.\n",
    "\n",
    "#### Static Scope and Block Structure:\n",
    "\n",
    "- The scope of a declaration is implicitly determined by where it appears in the program.\n",
    "- Code blocks group declarations and statements, often delimited by braces `{}` or keywords like `begin` and `end`.\n",
    "\n",
    "\n",
    "#### Static scope and block structure in C++\n",
    "\n",
    "\n",
    "# <center><img src=\"pictures/structure-C++.JPG\" width=\"600\"/>\n",
    "\n",
    "\n",
    "#### White Spaces:\n",
    "\n",
    "- Whitespaces are defined as tokens using space characters, tabs, and end-of-line characters.\n",
    "- In most languages, whitespaces and comments can occur between any two tokens and are generally ignored by the parser.\n",
    "\n",
    "#### Comments:\n",
    "\n",
    "- Comments are detected and discarded by the lexer.\n",
    "- They can be single-line or multi-line.\n",
    "- Lexical analyzers always find the next non-whitespace, non-comment token.\n",
    "\n",
    "#### Lexical Errors and Error Recovery:\n",
    "\n",
    "- Lexical errors occur when no token pattern matches the remaining input.\n",
    "- A \"panic mode\" recovery strategy involves deleting characters until a well-formed token is found.\n",
    "- Other recovery actions include deleting, inserting, replacing, or transposing characters.\n",
    "\n",
    "#### Lexical Analysis Challenges:\n",
    "\n",
    "- In some languages like Fortran, whitespace is insignificant, making lexical analysis challenging.\n",
    "- Lookahead is required to distinguish between tokens, and language design should aim to minimize lookahead.\n",
    "\n",
    "#### Lookahead:\n",
    "\n",
    "- Lookahead is necessary to decide where one token ends and the next begins.\n",
    "- It is required to disambiguate between similar constructs (e.g., `==` and `=`).\n",
    "- Some languages, like PL/1, where keywords are not reserved, may require more extensive lookahead for lexical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
