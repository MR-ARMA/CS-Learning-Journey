{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Automatic construction of Lexers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><img src=\"pictures/compiler.jpg\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lexer Construction Steps\n",
    "\n",
    "**Input: Token Specifications**\n",
    "- A list of regular expressions (RE) in priority order that define the patterns of tokens in a programming language.\n",
    "\n",
    "**Output: Lexer**\n",
    "- A program that reads an input stream and breaks it up into tokens based on the specified regular expressions.\n",
    "\n",
    "**Algorithm:**\n",
    "\n",
    "1. **Convert REs into NFAs:**\n",
    "   - Transform regular expressions into Non-deterministic Finite Automata (NFAs).\n",
    "   - Each regular expression corresponds to an NFA that recognizes the language defined by that expression.\n",
    "\n",
    "2. **Convert NFAs to DFA:**\n",
    "   - Convert NFAs to Deterministic Finite Automata (DFAs) for efficiency.\n",
    "   - Create a DFA that accepts the same language as the original NFA.\n",
    "\n",
    "3. **Convert DFA into Transition Table:**\n",
    "   - Create a transition table that represents the DFA.\n",
    "   - The table indicates the next state for each combination of current state and input symbol.\n",
    "\n",
    "#### The Lex/Flex Tool\n",
    "\n",
    "- **Lex/Flex** is a powerful tool for generating lexical analyzers automatically.\n",
    "- Lex programs describe the lexical analyzer to be generated.\n",
    "\n",
    "**Structure of Lex Programs:**\n",
    "```python\n",
    "{% manifest constants %}\n",
    "declarations\n",
    "%%\n",
    "translation rules\n",
    "%%\n",
    "auxiliary functions\n",
    "```\n",
    "**Translation Rules:**\n",
    "- Each rule has the form: `Pattern { Action }`.\n",
    "- Patterns are regular expressions, and actions are code fragments, typically in C.\n",
    "\n",
    "#### Lex Architecture\n",
    "\n",
    "- Describes how Lex works in terms of token recognition.\n",
    "- Lex takes a set of regular expressions and corresponding actions to create a lexer.\n",
    "\n",
    "# <center><img src=\"pictures/lex-work.JPG\" width=\"800\"/>\n",
    "\n",
    "\n",
    "#### Regular Expression to NFA\n",
    "\n",
    "- Illustrates the process of converting a regular expression to a Non-deterministic Finite Automaton (NFA).\n",
    "- Each construct in the regular expression corresponds to a state transition in the NFA.\n",
    "\n",
    "#### Converting NFA to DFA\n",
    "\n",
    "- Demonstrates the algorithm to convert NFAs to DFAs.\n",
    "- Each set of possible states in the NFA becomes one state in the DFA, resulting in a more efficient representation.\n",
    "\n",
    "#### DFA Minimization\n",
    "\n",
    "**Intuition:**\n",
    "- Two DFA states are equivalent if all subsequent behavior from those states is the same.\n",
    "\n",
    "**Procedure:**\n",
    "1. Create a table of state pairs.\n",
    "2. Mark cells where one state is final and the other is non-final.\n",
    "3. Mark pairs where transitions on the same symbol lead to marked pairs.\n",
    "4. Repeat step 3 until no unmarked pairs remain.\n",
    "5. Merge unmarked states to achieve a minimized DFA.\n",
    "\n",
    "#### Resolving Ambiguities in Lexers\n",
    "\n",
    "**Regular Expression Ambiguity:**\n",
    "- Ambiguity arises when regular expressions can match input in multiple ways.\n",
    "\n",
    "**Conflict Resolution in Lex:**\n",
    "1. **Longest/Maximal Match Rule:**\n",
    "   - Prefer a longer prefix over a shorter one.\n",
    "2. **Declaration Priority:**\n",
    "   - If the longest prefix matches multiple patterns, prefer the one listed first in the Lex program.\n",
    "\n",
    "#### The Flex Manual\n",
    "\n",
    "- An essential reference for using the Flex tool.\n",
    "- It provides detailed information on the Flex tool and its capabilities.\n",
    "- Refer to the provided appendix slide for in-depth insights.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
